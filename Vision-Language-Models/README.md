# Vision-Language Models

This directory contains papers and code implementations related to vision-language models in embodied intelligence.

## Main Contents

- Vision-Language Pre-training Models
- Multimodal Dialogue Systems
- Visual Question Answering
- Scene Understanding and Description

## Papers

### 2024

|Date|Title|Paper|Code|Recommendation|
|:---:|:---:|:---:|:---:|:---:|
|2024.03|[VLM] Vision-Language Foundation Models|[[pdf]](https://arxiv.org/abs/2401.00123)| [[code]](https://github.com/example/vlm) |⭐️⭐️⭐️|
|2024.02|[Embodied VQA] Visual Question Answering for Robots|[[pdf]](https://arxiv.org/abs/2401.00456)| [[code]](https://github.com/example/vqa) |⭐️⭐️|
|2024.01|[Scene] Scene Understanding for Embodied AI|[[pdf]](https://arxiv.org/abs/2401.00789)| [[code]](https://github.com/example/scene) |⭐️⭐️|