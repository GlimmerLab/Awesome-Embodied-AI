# Awesome-Embodied-AI

<div align='center'>
  <img src="assets/logo.svg" width=250px >
</div>

<div align='center'>
  <img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" >
  <img src="https://img.shields.io/badge/License-GPLv3.0-turquoise.svg" >
  <img src="https://img.shields.io/badge/PRs-Welcome-brightgreen.svg" >
  <a href="README.md">English</a>
</div>

## 📒简介

Awesome-Embodied-AI 是一个精心策划的具身智能相关论文和代码的集合。本仓库旨在为研究人员和开发者提供一个全面的具身智能研究资源，包括但不限于基础理论、视觉语言模型、机器人学习、强化学习等多个方向。

## 🎯特点

- 📚 全面的论文收集
- 💻 开源代码实现
- 🔍 详细的分类整理
- 🌟 重要论文推荐
- 📅 定期更新维护

## 📖目录

* [基础理论](Fundamental-Theory/README_CN.md)
* [视觉语言模型](Vision-Language-Models/README_CN.md)
* [机器人学习](Robot-Learning/README_CN.md)
* [强化学习](Reinforcement-Learning/README_CN.md)
* [多模态交互](Multimodal-Interaction/README_CN.md)
* [环境感知](Environment-Perception/README_CN.md)
* [运动规划](Motion-Planning/README_CN.md)
* [任务规划](Task-Planning/README_CN.md)
* [仿真平台](Simulation-Platforms/README_CN.md)

## 📊统计

- 论文总数：50+
- 代码实现：30+
- 最近更新：2024.03

## ©️引用

如果您在研究中使用了本仓库的内容，请引用：

```BibTeX
@misc{Awesome-Embodied-AI@2024,
  title={Awesome-Embodied-AI: A curated list of Awesome Embodied AI Papers with codes},
  url={https://github.com/GlimmerLab/Awesome-Embodied-AI},
  author={GlimmerLab etc},
  year={2024}
}
```

## 🤝贡献指南

我们欢迎所有形式的贡献，包括但不限于：
- 提交新的论文和代码
- 修正错误或更新过时信息
- 改进仓库结构和组织
- 提供建议和反馈

请通过 Issues 或 Pull Requests 提交您的贡献。

## 📜许可证

本项目采用 [GNU General Public License v3.0](LICENSE) 许可证。

## 🌟致谢

感谢所有为本项目做出贡献的研究者和开发者！

## 📬联系方式

- 项目负责人：[GlimmerLab](junli440883@gmail.com)
- 项目主页：[GitHub](https://github.com/GlimmerLab/Awesome-Embodied-AI)
<!-- - Twitter：[@GlimmerLab](https://twitter.com/GlimmerLab)
- Discord：[加入我们的社区](https://discord.gg/glimmerlab) -->

## 🌟贡献者

感谢所有贡献者：

<a href="https://github.com/GlimmerLab/Awesome-Embodied-AI/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=GlimmerLab/Awesome-Embodied-AI" />
</a>

使用 [contrib.rocks](https://contrib.rocks) 生成。

---

⭐️ 如果您觉得这个项目有帮助，欢迎 star 支持！